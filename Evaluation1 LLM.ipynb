{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f71e851",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T16:41:39.026756Z",
     "iopub.status.busy": "2023-12-11T16:41:39.026113Z",
     "iopub.status.idle": "2023-12-11T16:41:49.915395Z",
     "shell.execute_reply": "2023-12-11T16:41:49.913786Z"
    },
    "papermill": {
     "duration": 10.906366,
     "end_time": "2023-12-11T16:41:49.919453",
     "exception": false,
     "start_time": "2023-12-11T16:41:39.013087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pandas torch transformers\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8ab806b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T16:41:49.941666Z",
     "iopub.status.busy": "2023-12-11T16:41:49.940860Z",
     "iopub.status.idle": "2023-12-11T16:41:50.063946Z",
     "shell.execute_reply": "2023-12-11T16:41:50.061843Z"
    },
    "papermill": {
     "duration": 0.139617,
     "end_time": "2023-12-11T16:41:50.068962",
     "exception": false,
     "start_time": "2023-12-11T16:41:49.929345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "essays_train=pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99b3db91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T16:41:50.091311Z",
     "iopub.status.busy": "2023-12-11T16:41:50.090308Z",
     "iopub.status.idle": "2023-12-11T16:41:50.105868Z",
     "shell.execute_reply": "2023-12-11T16:41:50.104208Z"
    },
    "papermill": {
     "duration": 0.030821,
     "end_time": "2023-12-11T16:41:50.109569",
     "exception": false,
     "start_time": "2023-12-11T16:41:50.078748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts_train=pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d63d660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T16:41:50.132509Z",
     "iopub.status.busy": "2023-12-11T16:41:50.131531Z",
     "iopub.status.idle": "2023-12-11T16:41:50.177037Z",
     "shell.execute_reply": "2023-12-11T16:41:50.175402Z"
    },
    "papermill": {
     "duration": 0.061801,
     "end_time": "2023-12-11T16:41:50.180893",
     "exception": false,
     "start_time": "2023-12-11T16:41:50.119092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "complete_train=essays_train.merge(prompts_train, on='prompt_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c5dfd6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T16:41:50.202112Z",
     "iopub.status.busy": "2023-12-11T16:41:50.201578Z",
     "iopub.status.idle": "2023-12-11T16:41:50.224613Z",
     "shell.execute_reply": "2023-12-11T16:41:50.223229Z"
    },
    "papermill": {
     "duration": 0.037736,
     "end_time": "2023-12-11T16:41:50.228254",
     "exception": false,
     "start_time": "2023-12-11T16:41:50.190518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>instructions</th>\n",
       "      <th>source_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>0</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prompt_id                                               text  \\\n",
       "0  0059830c          0  Cars. Cars have been around since they became ...   \n",
       "1  005db917          0  Transportation is a large necessity in most co...   \n",
       "2  008f63e3          0  \"America's love affair with it's vehicles seem...   \n",
       "3  00940276          0  How often do you ride in a car? Do you drive a...   \n",
       "4  00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n",
       "\n",
       "   generated      prompt_name  \\\n",
       "0          0  Car-free cities   \n",
       "1          0  Car-free cities   \n",
       "2          0  Car-free cities   \n",
       "3          0  Car-free cities   \n",
       "4          0  Car-free cities   \n",
       "\n",
       "                                        instructions  \\\n",
       "0  Write an explanatory essay to inform fellow ci...   \n",
       "1  Write an explanatory essay to inform fellow ci...   \n",
       "2  Write an explanatory essay to inform fellow ci...   \n",
       "3  Write an explanatory essay to inform fellow ci...   \n",
       "4  Write an explanatory essay to inform fellow ci...   \n",
       "\n",
       "                                         source_text  \n",
       "0  # In German Suburb, Life Goes On Without Cars ...  \n",
       "1  # In German Suburb, Life Goes On Without Cars ...  \n",
       "2  # In German Suburb, Life Goes On Without Cars ...  \n",
       "3  # In German Suburb, Life Goes On Without Cars ...  \n",
       "4  # In German Suburb, Life Goes On Without Cars ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0440b76a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T16:41:50.252579Z",
     "iopub.status.busy": "2023-12-11T16:41:50.251921Z",
     "iopub.status.idle": "2023-12-11T16:41:50.263263Z",
     "shell.execute_reply": "2023-12-11T16:41:50.261446Z"
    },
    "papermill": {
     "duration": 0.02874,
     "end_time": "2023-12-11T16:41:50.267187",
     "exception": false,
     "start_time": "2023-12-11T16:41:50.238447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set,test_set=train_test_split(complete_train,test_size=.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28565d62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T16:41:50.289282Z",
     "iopub.status.busy": "2023-12-11T16:41:50.288690Z",
     "iopub.status.idle": "2023-12-11T16:41:50.442936Z",
     "shell.execute_reply": "2023-12-11T16:41:50.441488Z"
    },
    "papermill": {
     "duration": 0.17029,
     "end_time": "2023-12-11T16:41:50.447402",
     "exception": false,
     "start_time": "2023-12-11T16:41:50.277112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized text: ['this', 'is', 'a', 'test', 'sentence', '.']\n"
     ]
    }
   ],
   "source": [
    "local_model_dir = '/kaggle/input/bert-model'\n",
    "tokenizer = BertTokenizer.from_pretrained(local_model_dir)\n",
    "\n",
    "# Test the tokenizer\n",
    "text = \"This is a test sentence.\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(\"Tokenized text:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31b7d898",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T16:41:50.471239Z",
     "iopub.status.busy": "2023-12-11T16:41:50.470641Z",
     "iopub.status.idle": "2023-12-11T16:42:24.670094Z",
     "shell.execute_reply": "2023-12-11T16:42:24.668485Z"
    },
    "papermill": {
     "duration": 34.215553,
     "end_time": "2023-12-11T16:42:24.673431",
     "exception": false,
     "start_time": "2023-12-11T16:41:50.457878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_encoding=tokenizer(train_set['text'].to_list(), truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "# to list: bert_tokenizer converts list of text samples into tokenized representation\n",
    "#truncation=true: if text_sample exceeds the maximum length: it will be truncated\n",
    "#return_tensors='pt': It specifies that the output should be in PyTorch tensors. \n",
    "#BERT models typically expect input in the form of tensors.\n",
    "test_encoding=tokenizer(test_set['text'].to_list(), truncation=True, padding=True, max_length=128, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "033f6870",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T16:42:24.698172Z",
     "iopub.status.busy": "2023-12-11T16:42:24.697616Z",
     "iopub.status.idle": "2023-12-11T16:42:24.707891Z",
     "shell.execute_reply": "2023-12-11T16:42:24.705932Z"
    },
    "papermill": {
     "duration": 0.026369,
     "end_time": "2023-12-11T16:42:24.711216",
     "exception": false,
     "start_time": "2023-12-11T16:42:24.684847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels=torch.tensor(train_set['generated'].tolist())\n",
    "test_labels=torch.tensor(test_set['generated'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efb2dbc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T16:42:24.735548Z",
     "iopub.status.busy": "2023-12-11T16:42:24.734674Z",
     "iopub.status.idle": "2023-12-11T16:42:24.783853Z",
     "shell.execute_reply": "2023-12-11T16:42:24.782559Z"
    },
    "papermill": {
     "duration": 0.066386,
     "end_time": "2023-12-11T16:42:24.787466",
     "exception": false,
     "start_time": "2023-12-11T16:42:24.721080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# handling class imbalance\n",
    "class_counts=test_set['generated'].value_counts().to_list()\n",
    "class_weights=1/torch.tensor(class_counts,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a5be3fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T16:42:24.810321Z",
     "iopub.status.busy": "2023-12-11T16:42:24.809836Z",
     "iopub.status.idle": "2023-12-11T16:42:24.833647Z",
     "shell.execute_reply": "2023-12-11T16:42:24.832099Z"
    },
    "papermill": {
     "duration": 0.039634,
     "end_time": "2023-12-11T16:42:24.836962",
     "exception": false,
     "start_time": "2023-12-11T16:42:24.797328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weighted_random_sampler: more importance to under represented class\n",
    "#weights=class_weights[train_labels]: indicates to pay attention to samples from minority class\n",
    "#num_samples: generates as many sample as there are in training set\n",
    "# replacement: samples are drawn with replacement meaning that there is  random selection and possibility of sample being selected any no: of times\n",
    "weighted_sample=WeightedRandomSampler(weights=class_weights[train_labels], num_samples=len(train_labels), replacement=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d04133c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T16:42:24.860451Z",
     "iopub.status.busy": "2023-12-11T16:42:24.859643Z",
     "iopub.status.idle": "2023-12-11T16:42:24.867884Z",
     "shell.execute_reply": "2023-12-11T16:42:24.866325Z"
    },
    "papermill": {
     "duration": 0.023796,
     "end_time": "2023-12-11T16:42:24.871039",
     "exception": false,
     "start_time": "2023-12-11T16:42:24.847243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#input_ids: This is a sequence of \n",
    "#numerical IDs that correspond to each token in the input text.\n",
    "#attention_mask: indicates variable-length sequences \n",
    "#by indicating which parts of the sequence are padding and should not contribute to the model's understanding of the input.\n",
    "\n",
    "train_dataset=TensorDataset(train_encoding['input_ids'], train_encoding['attention_mask'], train_labels)\n",
    "test_dataset=TensorDataset(test_encoding['input_ids'], test_encoding['attention_mask'], test_labels)\n",
    "#dataloader organizes train set into batches of 8 and uses weighted_sampler to draw samples\n",
    "train_dataloader=DataLoader(train_dataset,batch_size=8,sampler=weighted_sample)\n",
    "#weighting is not necessary during testing, so no sampler, instead shuffle(in the same order as they are).\n",
    "test_dataloader=DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61666e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T16:42:24.893294Z",
     "iopub.status.busy": "2023-12-11T16:42:24.892726Z",
     "iopub.status.idle": "2023-12-11T16:42:30.984924Z",
     "shell.execute_reply": "2023-12-11T16:42:30.983582Z"
    },
    "papermill": {
     "duration": 6.107074,
     "end_time": "2023-12-11T16:42:30.988059",
     "exception": false,
     "start_time": "2023-12-11T16:42:24.880985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/bert-model and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "local_model_dir='/kaggle/input/bert-model'\n",
    "model=BertForSequenceClassification.from_pretrained(local_model_dir,num_labels=2)\n",
    "device=torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe55f3aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T16:42:31.013400Z",
     "iopub.status.busy": "2023-12-11T16:42:31.012054Z",
     "iopub.status.idle": "2023-12-11T16:42:31.022640Z",
     "shell.execute_reply": "2023-12-11T16:42:31.021476Z"
    },
    "papermill": {
     "duration": 0.027087,
     "end_time": "2023-12-11T16:42:31.025867",
     "exception": false,
     "start_time": "2023-12-11T16:42:30.998780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# optimizer is a crucial component responsible for adjusting parameters of model during training to minimize loss/error\n",
    "optimizer=AdamW(model.parameters(), lr=2e-5, no_deprecation_warning=True)\n",
    "device=torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcfeadc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T16:42:31.049186Z",
     "iopub.status.busy": "2023-12-11T16:42:31.047810Z",
     "iopub.status.idle": "2023-12-11T16:42:31.063858Z",
     "shell.execute_reply": "2023-12-11T16:42:31.062585Z"
    },
    "papermill": {
     "duration": 0.030872,
     "end_time": "2023-12-11T16:42:31.066853",
     "exception": false,
     "start_time": "2023-12-11T16:42:31.035981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2feb383",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T16:42:31.092050Z",
     "iopub.status.busy": "2023-12-11T16:42:31.090439Z",
     "iopub.status.idle": "2023-12-11T17:20:10.899546Z",
     "shell.execute_reply": "2023-12-11T17:20:10.897596Z"
    },
    "papermill": {
     "duration": 2259.836658,
     "end_time": "2023-12-11T17:20:10.914178",
     "exception": false,
     "start_time": "2023-12-11T16:42:31.077520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Training Loss: 0.05495787182893685\n",
      "Epoch 2, Average Training Loss: 0.0015406701410108287\n",
      "Epoch 3, Average Training Loss: 0.0005696529311219068\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    total_loss = 0.0  # Initialize total loss for the epoch\n",
    "    for batch in train_dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()  # Accumulate the loss for the batch\n",
    "    \n",
    "    # Print the average training loss for the epoch\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}, Average Training Loss: {average_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f400112a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T17:20:10.939308Z",
     "iopub.status.busy": "2023-12-11T17:20:10.938262Z",
     "iopub.status.idle": "2023-12-11T17:20:10.945807Z",
     "shell.execute_reply": "2023-12-11T17:20:10.944756Z"
    },
    "papermill": {
     "duration": 0.022945,
     "end_time": "2023-12-11T17:20:10.948270",
     "exception": false,
     "start_time": "2023-12-11T17:20:10.925325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "700b0972",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T17:20:10.972268Z",
     "iopub.status.busy": "2023-12-11T17:20:10.971546Z",
     "iopub.status.idle": "2023-12-11T17:21:08.352449Z",
     "shell.execute_reply": "2023-12-11T17:21:08.351139Z"
    },
    "papermill": {
     "duration": 57.396834,
     "end_time": "2023-12-11T17:21:08.355806",
     "exception": false,
     "start_time": "2023-12-11T17:20:10.958972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# no gradients calculation during model testing\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        # logits: raw predictions before applying softmax function\n",
    "        logits = outputs.logits\n",
    "        # raw scores into class predictions\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        # move the predictions from CPU and convert to numpy\n",
    "        all_preds.extend(preds.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc57d4ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T17:21:08.382090Z",
     "iopub.status.busy": "2023-12-11T17:21:08.380827Z",
     "iopub.status.idle": "2023-12-11T17:21:08.407543Z",
     "shell.execute_reply": "2023-12-11T17:21:08.406500Z"
    },
    "papermill": {
     "duration": 0.044952,
     "end_time": "2023-12-11T17:21:08.413664",
     "exception": false,
     "start_time": "2023-12-11T17:21:08.368712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9928\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       274\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.99       276\n",
      "   macro avg       0.50      0.50      0.50       276\n",
      "weighted avg       0.99      0.99      0.99       276\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy=accuracy_score(test_set['generated'],all_preds)\n",
    "print(f'Accuracy:{accuracy:.4f}')\n",
    "print('Classification Report: ')\n",
    "print(classification_report(test_set['generated'],all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb8d3d8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T17:21:08.438705Z",
     "iopub.status.busy": "2023-12-11T17:21:08.437902Z",
     "iopub.status.idle": "2023-12-11T17:22:04.960105Z",
     "shell.execute_reply": "2023-12-11T17:22:04.958848Z"
    },
    "papermill": {
     "duration": 56.549137,
     "end_time": "2023-12-11T17:22:04.974282",
     "exception": false,
     "start_time": "2023-12-11T17:21:08.425145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\n",
      "            id  predicted_probability\n",
      "597   d839e553               0.000271\n",
      "700   fdc74a07               0.000259\n",
      "1222  bc77d834               0.000260\n",
      "1145  a41f347b               0.000282\n",
      "602   d981ee62               0.000342\n",
      "...        ...                    ...\n",
      "506   b07f65ef               0.000288\n",
      "615   df0ceb07               0.000307\n",
      "365   7f84f1a7               0.000260\n",
      "828   318c7ac8               0.000287\n",
      "1281  d90606d4               0.000257\n",
      "\n",
      "[276 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# ... (previous code)\n",
    "\n",
    "# Initialize an empty list to store probabilities\n",
    "all_probabilities = []\n",
    "\n",
    "# no gradients calculation during model testing\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        # logits: raw predictions before applying softmax function\n",
    "        logits = outputs.logits\n",
    "        # calculate probabilities using softmax for the positive class\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
    "        # append probabilities to the list\n",
    "        all_probabilities.extend(probabilities)\n",
    "\n",
    "# Check the length\n",
    "print(len(all_probabilities))  # This should match the number of rows in your test_set DataFrame\n",
    "\n",
    "# Assign the probabilities to the 'predicted_probability' column\n",
    "test_set['predicted_probability'] = all_probabilities\n",
    "\n",
    "# ... (continue with the rest of your code)\n",
    "result_test=test_set[['id','predicted_probability']]\n",
    "print(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56a7f39b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T17:22:04.998915Z",
     "iopub.status.busy": "2023-12-11T17:22:04.998137Z",
     "iopub.status.idle": "2023-12-11T17:22:05.022744Z",
     "shell.execute_reply": "2023-12-11T17:22:05.021237Z"
    },
    "papermill": {
     "duration": 0.040994,
     "end_time": "2023-12-11T17:22:05.026175",
     "exception": false,
     "start_time": "2023-12-11T17:22:04.985181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_final=pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\")\n",
    "test_final_encoding=tokenizer(test_final['text'].to_list(),truncation=True,padding=True,max_length=128,return_tensors='pt')\n",
    "test_final_dataset=TensorDataset(test_final_encoding['input_ids'],test_final_encoding['attention_mask'])\n",
    "test_final_dataloader=DataLoader(test_final_dataset, batch_size=8,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3aab15c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T17:22:05.050690Z",
     "iopub.status.busy": "2023-12-11T17:22:05.050195Z",
     "iopub.status.idle": "2023-12-11T17:22:05.157961Z",
     "shell.execute_reply": "2023-12-11T17:22:05.156154Z"
    },
    "papermill": {
     "duration": 0.123774,
     "end_time": "2023-12-11T17:22:05.161017",
     "exception": false,
     "start_time": "2023-12-11T17:22:05.037243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# ... (previous code)\n",
    "\n",
    "# Initialize an empty list to store probabilities\n",
    "all_probabilities = []\n",
    "\n",
    "# no gradients calculation during model testing\n",
    "with torch.no_grad():\n",
    "    for batch in test_final_dataloader:\n",
    "        input_ids, attention_mask = batch\n",
    "        input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        # logits: raw predictions before applying softmax function\n",
    "        logits = outputs.logits\n",
    "        # calculate probabilities using softmax for the positive class\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
    "        # append probabilities to the list\n",
    "        all_probabilities.extend(probabilities)\n",
    "\n",
    "# Check the length\n",
    "print(len(all_probabilities))  # This should match the number of rows in your test_set DataFrame\n",
    "\n",
    "# Assign the probabilities to the 'predicted_probability' column\n",
    "test_final['predicted_probability'] = all_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8b1057a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T17:22:05.186097Z",
     "iopub.status.busy": "2023-12-11T17:22:05.185250Z",
     "iopub.status.idle": "2023-12-11T17:22:05.192010Z",
     "shell.execute_reply": "2023-12-11T17:22:05.191115Z"
    },
    "papermill": {
     "duration": 0.022298,
     "end_time": "2023-12-11T17:22:05.194709",
     "exception": false,
     "start_time": "2023-12-11T17:22:05.172411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_final=pd.DataFrame({'id': test_final['id'], 'generated': test_final['predicted_probability']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36089ed8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T17:22:05.219282Z",
     "iopub.status.busy": "2023-12-11T17:22:05.218347Z",
     "iopub.status.idle": "2023-12-11T17:22:05.228270Z",
     "shell.execute_reply": "2023-12-11T17:22:05.226613Z"
    },
    "papermill": {
     "duration": 0.025547,
     "end_time": "2023-12-11T17:22:05.231050",
     "exception": false,
     "start_time": "2023-12-11T17:22:05.205503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  generated\n",
      "0  0000aaaa   0.004119\n",
      "1  1111bbbb   0.003976\n",
      "2  2222cccc   0.005600\n"
     ]
    }
   ],
   "source": [
    "print(result_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16d7703b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T17:22:05.255675Z",
     "iopub.status.busy": "2023-12-11T17:22:05.255152Z",
     "iopub.status.idle": "2023-12-11T17:22:05.266142Z",
     "shell.execute_reply": "2023-12-11T17:22:05.264618Z"
    },
    "papermill": {
     "duration": 0.027573,
     "end_time": "2023-12-11T17:22:05.269766",
     "exception": false,
     "start_time": "2023-12-11T17:22:05.242193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_file_path = '/kaggle/working/submission.csv'\n",
    "result_final.to_csv(submission_file_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d40764",
   "metadata": {
    "papermill": {
     "duration": 0.010745,
     "end_time": "2023-12-11T17:22:05.291686",
     "exception": false,
     "start_time": "2023-12-11T17:22:05.280941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6888007,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "datasetId": 4147700,
     "sourceId": 7177117,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30615,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2433.655671,
   "end_time": "2023-12-11T17:22:08.703371",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-11T16:41:35.047700",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
